---
title: "Hands-on Ex05: Visual Multivariate Analysis"
author: "Li Ziyi"
date: 11 February 2023
date-modified: "`r Sys.Date()`"
execute:
  echo: true
  eval: true
  warning: false
format: html
editor: visual
---

# Visualising correlation matrices with R

```{r}
pacman::p_load(corrplot,
               tidyverse,
               ggstatsplot,
               ggcorrplot,
               plotly,
               seriation,
               dendextend,
               heatmaply,
               GGally,
               parallelPlot)

```

In this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.

```{r}
wine <- read.csv("Data/wine_quality.csv")

```

Beside quality and type, the rest of the variables are numerical and continuous data type.

## Basic correlation matrix with the upper corner hidden

```{r}
pairs(wine[, 1:11],
      upper.panel = NULL)


```

## Basic correlation matrix with correlation coefficients

To show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.

```{r}
panel.cor <- function(x, y, digits=2, prefix="", cex.cor, ...) {
usr <- par("usr")
on.exit(par(usr))
par(usr = c(0, 1, 0, 1))
r <- abs(cor(x, y, use="complete.obs"))
txt <- format(c(r, 0.123456789), digits=digits)[1]
txt <- paste(prefix, txt, sep="")
if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
text(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)
}

pairs(wine[,2:12], 
      upper.panel = panel.cor)


```

## Visualizing correlation matrix using ggcormat()

One of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations).

Corrgram data visualisation technique is able to overcome this problem, .

```{r}
ggstatsplot::ggcorrmat(
  data = wine,
  cor.vars = 1:11,
  ggcorrplot.args = list(outline.color = "black",
                         hc.order = TRUE,
                         tl.cex = 10),
  title    = "Correlogram for wine dataset",
  subtitle = "Four pairs are no significant at p < 0.05"
)


```

```{r}
ggstatsplot::ggcorrmat(
  data = wine, 
  cor.vars = 1:11,
  ggcorrplot.args = list(outline.color = "black", 
                         hc.order = TRUE,
                         tl.cex = 10),
  title    = "Correlogram for wine dataset",
  subtitle = "Four pairs are no significant at p < 0.05"
) 

ggplot.component = list(
    theme(text=element_text(size=5),
      axis.text.x = element_text(size = 8),
      axis.text.y = element_text(size = 8)))

```

Take note the sub-code chunk above can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.

## Building multiple correlation plots

Faceting is not available in ggcorrmat() but can be found in the grouped_ggcorrmat() of ggstatsplot.

```{r}
grouped_ggcorrmat(
  data = wine,
  cor.vars = 1:11,
  grouping.var = type,
  type = "robust",
  p.adjust.method = "holm",
  plotgrid.args = list(ncol = 2),
  ggcorrplot.args = list(outline.color = "black", 
                         hc.order = TRUE,
                         tl.cex = 10),
  annotation.args = list(
    tag_levels = "a",
    title = "Correlogram for wine dataset",
    subtitle = "The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity",
    caption = "Dataset: UCI Machine Learning Repository"
  )
)


```

Take note that:

1.  To build a facet plot, the only argument needed is grouping.var.

2.  Behind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.

3.  Likewise, annotation.args argument is calling plot annotation arguments of patchwork package.

## Correlation plot with corrplot

-   The default visual object in corrplot used to plot the corrgram is circle.

-   The default layout of the corrgram is a symmetric matrix. We can switch in between "full", "upper" and "lower" using parameter "type".

-   The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.

```{r}
wine.cor <- cor(wine[, 1:11])
corrplot(wine.cor,
         type = "lower",
         diag = FALSE,
         tl.col = "black")

```

Some other parameters that can be changed to customise the layout such as: tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset.

## Correlation plot with corrplot and mixed layout

```{r}
corrplot.mixed(wine.cor, 
               lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")

```

## Correlation plot with corrplot and the significance test

```{r}
wine.sig = cor.mtest(wine.cor, conf.level= .95)

corrplot(wine.cor,
         method = "number",
         type = "lower",
         diag = FALSE,
         tl.col = "black",
         tl.srt = 45,
         p.mat = wine.sig$p,
         sig.level = .05)
```

## Reorder a corrgram

Matrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. "original"). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are: AOE, FPC, hclust and alphabet.

```{r}
corrplot.mixed(wine.cor, 
               lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               order="AOE",
               tl.col = "black")

```

# Heatmap for visualising and analysing multivariate data

Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.

Some of packages that will be used for this section would be mainly: seriation, dendextend, heatmaply, tidyverse.

The data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.

```{r}
wh <- read_csv("data/WHData-2018.csv")

```

We change the rows by country name instead of row number.

```{r}
row.names(wh) <- wh$Country
```

The data was loaded into a data frame, but it has to be a data matrix to produce heatmap.

```{r}
wh1 <- dplyr::select(wh, c(3, 7:12))
wh_matrix <- data.matrix(wh)

```

There are many R packages and functions can be used to drawing static heatmaps, they are:

-   heatmap()of R stats package. It draws a simple heatmap.

-   heatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.

-   pheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.

-   ComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis).

-   superheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types.

## heatmap() of R stats

The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.

```{r}
wh_heatmap <- heatmap(wh_matrix,
                      Rowv=NA, Colv=NA)


```

## A cluster heatmap

```{r}
wh_heatmap <- heatmap(wh_matrix,
                      scale = 'column',
                      margins = c(10, 4),
                      cexRow = 0.6,
                      cexCol = 0.8)
```

The order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.

The Happiness Score variable have relatively higher values, therefore it might make other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs. Margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively.

## Interactive heatmap using heatmaply

Different from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap. The text label of each raw, on the other hand, is placed on the right hand side of the heat map.

```{r}
heatmaply(wh_matrix[, -c(1, 2, 4, 5)])


```

### Data transformation supported by heatmaply()

#### Scaling method

When all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.

In such a case, each value would reflect the distance from the mean in units of standard deviation.

The scale argument in heatmaply() supports column and row scaling.

```{r}
heatmaply(wh_matrix[, -c(1, 2, 4, 5)],
          scale = "column")

```

#### Normalising method

```{r}
heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))

```

When variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations. This preserves the shape of each variable's distribution while making them easily comparable on the same "scale". Different from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.

#### Percentising method

```{r}
heatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))
```

This is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank. This is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile. The benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it. Similar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.

### Clustering algorithm

heatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:

-   distfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options "pearson", "spearman" and "kendall" can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).

-   hclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.

-   dist_method default is NULL, which results in "euclidean" to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is "dist"" hence this can be one of "euclidean", "maximum", "manhattan", "canberra", "binary" or "minkowski".

-   hclust_method default is NULL, which results in "complete" method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of "ward.D", "ward.D2", "single", "complete", "average" (= UPGMA), "mcquitty" (= WPGMA), "median" (= WPGMC) or "centroid" (= UPGMC).

In general, a clustering model can be calibrated either manually or statistically.

#### Manual approach

Using hierarchical clustering algorithm with "Euclidean distance" and "ward.D" method.

```{r}
heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),
          dist_method = "euclidean",
          hclust_method = "ward.D")


```

#### Statistical approach

The best clustering method and number of cluster would be determined using the dend_expend() and find_k() functions of dendextend package.

```{r}
wh_d <- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = "euclidean")
dend_expend(wh_d)[[3]]

```

The output table shows that "average" method should be used because it gave the high optimum value.

Next, find_k() is used to determine the optimal number of cluster.

```{r}
wh_clust <- hclust(wh_d, method = "average")
num_k <- find_k(wh_clust)
plot(num_k)
```

Figure above shows that k=3 would be good.

Therefore,

```{r}
heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),
          dist_method = "euclidean",
          hclust_method = "average",
          k_row = 3)
```

#### Seriation

One of the problems with hierarchical clustering is that it doesn't actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can't end up between A and B, but it doesn't tell you which way to flip the A+B cluster. It doesn't tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.

heatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.

Here we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.

```{r}
heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),
          seriate = "OLO")
```

Or we can choose "GW" instead of "OLO". GW aims for the same goal but uses a potentially faster heuristic.

```{r}
heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),
          seriate = "GW")

```

The option of 'mean' would give the output that is similar to what we would get from heatmap functions in other packages like gplots::heatmap.2

```{r}
heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),
          seriate = "mean")
```

The option "none" would give the dendrograms without any rotations that is based on the data matrix.

```{r}
heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),
          seriate = "none")
```

### Color palettes

The default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.

```{r}
heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),
          seriate = "none",
          colors = Blues)

```

### Other cartographic advantages from heatmaply

In the code chunk below, some of following arguments are used:

-   k_row is used to produce 5 groups.

-   margins is used to change the top margin to 60 and row margin to 200.

-   fontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.

-   main is used to write the main title of the plot.

-   xlab and ylab are used to write the x-axis and y-axis labels respectively.

```{r}
heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),
          Colv=NA,
          seriate = "none",
          colors = Blues,
          k_row = 5,
          margins = c(NA,200,60,NA),
          fontsize_row = 4,
          fontsize_col = 5,
          main="World Happiness Score and Variables by Country, 2018 \nDataTransformation using Normalise Method",
          xlab = "World Happiness Indicators",
          ylab = "World Countries"
          )
```

# To be continued (incomplete yet... Parallel & Ternary...)

```{r}
pop_data <- read_csv("data/respopagsex2000to2018_tidy.csv") 

```

Use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.

```{r}
agpop_mutated <- pop_data %>%
  mutate(`Year` = as.character(Year))%>%
  spread(AG, Population) %>%
  mutate(YOUNG = rowSums(.[4:8]))%>%
  mutate(ACTIVE = rowSums(.[9:16]))  %>%
  mutate(OLD = rowSums(.[17:21])) %>%
  mutate(TOTAL = rowSums(.[22:24])) %>%
  filter(Year == 2018)%>%
  filter(TOTAL > 0)

```

```{r}
ggtern::ggtern(data = agpop_mutated,
       aes(x = YOUNG,
           y = ACTIVE, 
           z = OLD)) +
  geom_point()

```

```{r}
ggtern::ggtern(data = agpop_mutated, 
       aes(x = YOUNG,
           y = ACTIVE, 
           z = OLD)) +
  geom_point() +
  labs(title = "Population structure, 2015") 

```

```{r}
wh <- read.csv("Data/WHData-2018.csv")

```

```{r}
row.names(wh) <- wh$Country

```

```{r}
wh1 <- dplyr::select(wh, c(3, 7:12))
wh_matrix <- data.matrix(wh)

```

```{r}
wh_heatmap <- heatmap(wh_matrix,
                      Rowv=NA, Colv=NA)


```

```{r}
wh_heatmap <- heatmap(wh_matrix,
                      scale="column",
                      cexRow = 0.6, 
                      cexCol = 0.8,
                      margins = c(10, 4))

```

```{r}
heatmaply(mtcars)

```

```{r}
heatmaply(wh_matrix[, -c(1, 2, 4, 5)])


```

```{r}
heatmaply(wh_matrix[, -c(1, 2, 4, 5)],
          scale = "column")

```

```{r}
heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))
```

```{r}
heatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))
```

```{r}
heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),
          dist_method = "euclidean",
          hclust_method = "ward.D")

```

```{r}

ggparcoord(data = wh, 
           columns = c(7:12))
```

```{r}

ggparcoord(data = wh, 
           columns = c(7:12), 
           groupColumn = 2,
           scale = "uniminmax",
           alphaLines = 0.2,
           boxplot = TRUE, 
           title = "Parallel Coordinates Plot of World Happines Variables")
```
